{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before run\n",
    "\n",
    "```\n",
    "# create a python virtualenv for separating the dependencies\n",
    "virtualenv virtualenv\n",
    "\n",
    "# enter the virtualenv\n",
    "source virtualenv/bin/activate\n",
    "\n",
    "# install the dependencies\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Please run the first frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# First, check that the dataset has been installed on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is present on the machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATA_FOLDER = './data'\n",
    "\n",
    "log = print\n",
    "\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.mkdir(DATA_FOLDER)\n",
    "\n",
    "if not os.path.exists(DATA_FOLDER + '/evaluation'):\n",
    "    os.mkdir(DATA_FOLDER + '/evaluation')\n",
    "\n",
    "if not os.path.exists(f'{DATA_FOLDER}/Info_UserData.csv'):\n",
    "    import kaggle\n",
    "\n",
    "    kaggle.api.authenticate()\n",
    "    log('Download dataset...')\n",
    "    kaggle.api.dataset_download_files('junyiacademy/learning-activity-public-dataset-by-junyi-academy',\n",
    "                                      path=DATA_FOLDER, unzip=True)\n",
    "    log('Dataset downloaded.')\n",
    "else:\n",
    "    log(\"The dataset is present on the machine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the dataset: \n",
      "Info_Content.csv\n",
      "Info_UserData.csv\n",
      "Log_Problem.csv\n",
      "clusters.csv\n",
      "clusters_.csv\n",
      "clusters_all.csv\n",
      "Info_Content.csv\n",
      "Info_Content_subset.csv\n",
      "Info_UserData.csv\n",
      "Info_UserData_subset.csv\n",
      "Log_Problem.csv\n",
      "Log_Problem_subset - Copy.csv\n",
      "Log_Problem_subset.csv\n",
      "Log_Problem_subset.csv.bak\n",
      "reduced.csv\n",
      "eval_error_5splitss.txt\n",
      "eval_mean_errors_5splits.txt\n",
      "X_subset_w_level_id2_level_id3.pkl\n",
      "y_subset_w_level_id2_level_id3.pkl\n",
      "data_loader.cpython-310.pyc\n",
      "data_preprocessing.cpython-310.pyc\n",
      "data_visualization.cpython-310.pyc\n",
      "feature_categorization.cpython-310.pyc\n"
     ]
    }
   ],
   "source": [
    "print('Files in the dataset: ')\n",
    "for dirname, _, filenames in os.walk(DATA_FOLDER):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "Includes functions to Ordinal Encode, One-hot encode, scale and perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from data_visualization import plot_columns_of_df\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "####Preproccesing steps\n",
    "# 0. Load data\n",
    "# 1. Categorize features and encode accordingly\n",
    "# 2. Handle missing data\n",
    "# 3. Visualize\n",
    "# 4. Identify and remove outliers\n",
    "# 5. Potentially enrich data with feature engineering\n",
    "\n",
    "def scale(df, scaler=\"standard\"):\n",
    "    \"\"\"\n",
    "    Standardize data with scikit learn scaler\n",
    "    :param df: dataframe with data to be scaled\n",
    "    :param scaler: method of scaling\n",
    "    :return: scaled df\n",
    "    \"\"\"\n",
    "    if scaler == \"standard\":\n",
    "        scaler = StandardScaler()  # z = (x - u) / s, where u is column mean, and s is std. dev\n",
    "    elif scaler == \"minmax\":\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))  # scales columns to given range.\n",
    "    else:\n",
    "        scaler = MaxAbsScaler()\n",
    "\n",
    "    scaler.fit(df)\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    return pd.DataFrame(scaled, columns=df.columns)\n",
    "\n",
    "\n",
    "def unix_encode(df, column_names=[]):\n",
    "    \"\"\"\n",
    "    Encode date to unix format (sec/min/hour since unix epoch), that can be used for clustering/prediction\n",
    "    A kind of ugly implementation trying to speed up to_datetime by providing the relevant time formats\n",
    "    (There is a 10-100x speed up to give correct format)\n",
    "    :param df:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    time_columns = np.array([])\n",
    "    t_formats = ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S %Z']\n",
    "    for column in column_names:\n",
    "        success = False\n",
    "        # temp = (pd.to_datetime(df[column].iloc[:, 0]) - pd.Timestamp(\"1970-01-01\"))\n",
    "        for t_format in t_formats:\n",
    "            if not success:\n",
    "                try:\n",
    "                    temp = pd.to_datetime(df[column], format=t_format)  # Takes 15 sec for subset on df_pr\n",
    "                    success = True\n",
    "                except:\n",
    "                    print(\"incorrect time format {}\".format(t_format))\n",
    "\n",
    "        temp -= temp.min()\n",
    "        temp //= pd.Timedelta('15m')\n",
    "        if time_columns.shape[0] == 0:\n",
    "            time_columns = np.array(temp)\n",
    "        else:\n",
    "            time_columns = np.vstack((time_columns, temp))\n",
    "\n",
    "    return pd.DataFrame(time_columns.T, columns=column_names)\n",
    "\n",
    "\n",
    "def ordinal_encode(df, column_names=[]):\n",
    "    \"\"\"\n",
    "      ordinal-encode features\n",
    "      :param df: dataframe with only the columns to be one-hot-encoded\n",
    "      :param column_names: names of the columns to be one-hot-encoded\n",
    "      :return: one-hot-encoded columns ready to be concatenated with original dataframe\n",
    "      \"\"\"\n",
    "    encoded_data = np.array([])\n",
    "    mappings = \\\n",
    "        {\n",
    "            'difficulty': {'easy': 0, 'normal': 1, 'unset': 1, 'hard': 2},\n",
    "            'learning_stage': {'elementary': 0, 'junior': 1, 'senior': 2}\n",
    "        }\n",
    "    for column in column_names:\n",
    "        try:\n",
    "            mapping = mappings[column]\n",
    "        except:\n",
    "            print(\n",
    "                \"Please add ordinal mapping to ordinal_dict in 'ordinal_encode'-function in data/data_preprocessing.py\")\n",
    "        temp = list(map(lambda x: mapping[x], df[column]))\n",
    "        if encoded_data.shape[0] == 0:\n",
    "            encoded_data = np.array(temp)\n",
    "        else:\n",
    "            encoded_data = np.vstack((encoded_data, temp))\n",
    "    df_encoded = pd.DataFrame(encoded_data.T, columns=column_names)\n",
    "    return df_encoded, column_names\n",
    "\n",
    "\n",
    "def one_hot_encode(df, column_names=['gender', 'is_self_coach']):\n",
    "    \"\"\"\n",
    "    one-hot-encode categorical features\n",
    "    :param df: dataframe with only the columns to be one-hot-encoded\n",
    "    :param column_names: names of the columns to be one-hot-encoded\n",
    "    :return: one-hot-encoded columns ready to be concatenated with original dataframe\n",
    "    \"\"\"\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(df)\n",
    "    # print(enc.categories_)\n",
    "    column_names = enc.get_feature_names(column_names)\n",
    "\n",
    "    encoded_data = enc.transform(df).toarray()\n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=column_names)\n",
    "    return df_encoded, column_names, enc\n",
    "\n",
    "\n",
    "def extract_additional_user_features(df_u, df_problems, df_content):\n",
    "    \"\"\"\n",
    "    intendend purpose: extract user features from problems. Potentially using map_reduce\n",
    "    # exercise_per_level\n",
    "    # avg_time_spend\n",
    "    # avg_correct\n",
    "    # problem_solved\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Get features based on content\n",
    "    problem_content = df_problems.merge(df_content)\n",
    "    encoded_df, cols = ordinal_encode(problem_content[[\"difficulty\", \"learning_stage\"]],\n",
    "                                      column_names=[\"difficulty\", \"learning_stage\"])\n",
    "    problem_content[cols] = encoded_df[cols]\n",
    "    problem_content_grouped = problem_content.groupby(\"uuid\").agg({\n",
    "        \"is_correct\": \"mean\",\n",
    "        \"total_sec_taken\": \"mean\",\n",
    "        \"upid\": \"count\",\n",
    "        \"level\": [\"mean\", \"max\"],\n",
    "        \"used_hint_cnt\": \"mean\",\n",
    "        \"difficulty\": \"mean\",\n",
    "        \"learning_stage\": \"mean\",\n",
    "    })\n",
    "    cols = [\n",
    "        \"correct_percentage\",\n",
    "        \"time_spent\",\n",
    "        \"problems_attempted\",\n",
    "        \"average_level\", \"max_level\",\n",
    "        \"average_hints\",\n",
    "        \"avg_difficulty\",\n",
    "        \"avg_learning_stage\",\n",
    "    ]\n",
    "    problem_content_grouped.columns = cols\n",
    "\n",
    "    users = df_u.merge(problem_content_grouped, left_on=\"uuid\", right_on=\"uuid\")\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def _extract_additional_user_features(df_u, df_problems, df_content):\n",
    "    \"\"\"\n",
    "    intendend purpose: extract user features from problems. Potentially using map_reduce\n",
    "    # exercise_per_level\n",
    "    # avg_time_spend\n",
    "    # avg_correct\n",
    "    # problem_solved\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    os.system(\"python sandbox/MapReduceSandbox.py data/csv_files/Log_Problem.csv > data/csv_files/reduced.csv\")\n",
    "    reduced = pd.read_csv(\"data/csv_files/reduced.csv\",\n",
    "                          names=[\"uuid\", \"problems_attempted\", \"time_spent\", \"average_level\", \"correct_percentage\",\n",
    "                                 \"max_level\", \"avg_learning_stage\", \"avg_difficulty\", \"average_hints\"], index_col=False)\n",
    "\n",
    "\n",
    "    users = df_u.merge(reduced, left_on=\"uuid\", right_on=\"uuid\")\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def extract_additional_problem_features(df_ex):\n",
    "    \"\"\"\n",
    "    :param df_ex:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def preprocess_df(df, o_features) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :param o_features: object features as described in data/feature_categorization.py\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f, f_time, f_OR, f_OH, f_meta, f_scale = o_features.features, o_features.features_to_be_time_encoded, o_features.features_to_be_OR_encoded, o_features.features_to_be_OH_encoded, o_features.features_meta, o_features.features_to_be_scaled\n",
    "    df_f, df_time, df_OR, df_OH, df_meta, df_scale = df[f], df[f_time], df[f_OR], df[f_OH], df[f_meta], df[f_scale]\n",
    "\n",
    "    if f_time:  # if not empty then unix encode\n",
    "        df_time = unix_encode(df_time,\n",
    "                              f_time)  # Takes a significant amount of time to compute (for subset it is approx 20 seconds)\n",
    "\n",
    "    if f_scale:\n",
    "        df_scale = scale(df_scale)\n",
    "\n",
    "    if f_OR:\n",
    "        df_OR, column_names_OR = ordinal_encode(df_OR, f_OR)\n",
    "\n",
    "    if f_OH:\n",
    "        for column in df_OH.columns:\n",
    "            if df_OH[column].hasnans:\n",
    "                df_OH[column] = df_OH[column].astype('string').fillna(\"unspecified\")\n",
    "\n",
    "        df_OH, column_names_OH, enc_OH = one_hot_encode(df_OH, f_OH)\n",
    "    dfs = [df_f, df_time, df_OR, df_OH, df_meta, df_scale]\n",
    "    df_counter = 0\n",
    "    for df_ in dfs:\n",
    "        if df_.shape[1] != 0:\n",
    "            df_counter += 1\n",
    "            if df_counter == 1:\n",
    "                df_final = df_\n",
    "            else:\n",
    "                df_final = pd.concat([df_final, df_], axis=1)\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def remove_outliers_by_quantile(df, columns, quantiles):\n",
    "    for column, quantile_ in zip(columns, quantiles):\n",
    "        index_names = df[(df[column] > df[column].quantile(quantile_))].index\n",
    "        df.drop(index_names, inplace=True)\n",
    "    return df\n",
    "\n",
    "class U_features():\n",
    "    def __init__(self,\n",
    "                 features=['user_grade', 'has_teacher_cnt', 'has_student_cnt', 'has_class_cnt',\n",
    "                           \"correct_percentage\", \"problems_attempted\", \"average_level\", \"max_level\",\n",
    "                           \"average_hints\", \"avg_difficulty\", \"avg_learning_stage\"],\n",
    "                 features_to_be_time_encoded=['first_login_date_TW'], features_to_be_OR_encoded=[],\n",
    "                 features_to_be_OH_encoded=['gender', 'user_city', 'is_self_coach'], features_meta=['uuid'],\n",
    "                 features_to_be_scaled=['points', \"correct_percentage\", \"time_spent\", 'belongs_to_class_cnt',\n",
    "                                        \"badges_cnt\"]):\n",
    "        self.features = features\n",
    "        self.features_to_be_time_encoded = features_to_be_time_encoded\n",
    "        self.features_to_be_scaled = features_to_be_scaled\n",
    "        self.features_to_be_OR_encoded = features_to_be_OR_encoded\n",
    "        self.features_to_be_OH_encoded = features_to_be_OH_encoded\n",
    "        self.features_meta = features_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Now, we load data from the 3 files: Users, Problems and Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "def load_data_raw():\n",
    "    df_u = pd.read_csv(f'{DATA_FOLDER}/Info_UserData.csv')\n",
    "    df_pr = pd.read_csv(f'{DATA_FOLDER}/Log_Problem.csv')\n",
    "    df_ex = pd.read_csv(f'{DATA_FOLDER}/Info_Content.csv')\n",
    "    return df_u, df_pr, df_ex\n",
    "\n",
    "\n",
    "def remove_problems_with_total_time_outliers(df_pr):\n",
    "    limit = np.quantile(df_pr['total_sec_taken'], 0.98)\n",
    "    new_df_pr = df_pr[df_pr['total_sec_taken'] < limit]\n",
    "    return new_df_pr\n",
    "\n",
    "# if `log` is undefined then please run the first frame\n",
    "log(\"Loading data...\")\n",
    "df_u, df_pr, df_c = load_data_raw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract additional features\n",
    "\n",
    "To improve the user clustering, we extract additional features\n",
    "\n",
    "OBS: You can only run `USE_MAPREDUCE` if you have MrJob installed on your computer - and if you have the file `data/MapReduceSandbox.py` from the project. MapReduce takes ~20 times as long, so be warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction...\n"
     ]
    }
   ],
   "source": [
    "df_pr = remove_problems_with_total_time_outliers(df_pr)\n",
    "\n",
    "log(\"Feature extraction...\")\n",
    "\n",
    "USE_MAPREDUCE = False\n",
    "if USE_MAPREDUCE:\n",
    "    X = _extract_additional_user_features(df_u, df_pr, df_c)\n",
    "else:\n",
    "    X = extract_additional_user_features(df_u, df_pr, df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>gender</th>\n",
       "      <th>points</th>\n",
       "      <th>badges_cnt</th>\n",
       "      <th>first_login_date_TW</th>\n",
       "      <th>user_grade</th>\n",
       "      <th>user_city</th>\n",
       "      <th>has_teacher_cnt</th>\n",
       "      <th>is_self_coach</th>\n",
       "      <th>has_student_cnt</th>\n",
       "      <th>belongs_to_class_cnt</th>\n",
       "      <th>has_class_cnt</th>\n",
       "      <th>problems_attempted</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>average_level</th>\n",
       "      <th>correct_percentage</th>\n",
       "      <th>max_level</th>\n",
       "      <th>avg_learning_stage</th>\n",
       "      <th>avg_difficulty</th>\n",
       "      <th>average_hints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y2RcCdmUJAYPUAIDElo4nE9KrkLLFzUIRdexG+ipaZQ=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18300</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>kh</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J7Tbo1x2WtRpPuXeX7lWT9tkzWlSJeubl8UWjNmHh+4=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15525</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2</td>\n",
       "      <td>ntpc</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Dm50WJCc9EQjr4Ar8SPukhnsTeS+kwX+9FyUI1o57k=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101353</td>\n",
       "      <td>11</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2</td>\n",
       "      <td>kh</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADL8ZENEcGUW3bCQg4t8gA0tJR9R6H5OYwr+TCPb5oY=</td>\n",
       "      <td>male</td>\n",
       "      <td>7503</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2</td>\n",
       "      <td>kh</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5eCvpCJiXsYg8jNhQAz8JltX6G0LSWpFb86a2GVuinA=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12825</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>3</td>\n",
       "      <td>ntpc</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54299</th>\n",
       "      <td>yY0/JhgPot0/jgNGGKXiM+r47EA6HyxjxL5HBCe5cJE=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6300</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>9</td>\n",
       "      <td>ylc</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54300</th>\n",
       "      <td>1ISypO5ve8GgsJ2bgEW87eqdOIEAEqPfWeea52SndWo=</td>\n",
       "      <td>male</td>\n",
       "      <td>32937</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>9</td>\n",
       "      <td>ttct</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54301</th>\n",
       "      <td>xoUBGAzyfHBkDa/YjwWn3zpZCzr3FUpAFd8qMj2fIcA=</td>\n",
       "      <td>male</td>\n",
       "      <td>17453</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>9</td>\n",
       "      <td>chc</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54302</th>\n",
       "      <td>ESAeVlIpxgtgb2EtZb8K+plFLqKch5ffAgRzKnQqTQ4=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2393</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>10</td>\n",
       "      <td>tc</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54303</th>\n",
       "      <td>hkZZTOTi9MpjU38ctwOSK3O4g12JZt2ykeYS7nJsJkc=</td>\n",
       "      <td>female</td>\n",
       "      <td>293891</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>12</td>\n",
       "      <td>tp</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54304 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               uuid  gender  points  \\\n",
       "0      Y2RcCdmUJAYPUAIDElo4nE9KrkLLFzUIRdexG+ipaZQ=     NaN   18300   \n",
       "1      J7Tbo1x2WtRpPuXeX7lWT9tkzWlSJeubl8UWjNmHh+4=     NaN   15525   \n",
       "2      6Dm50WJCc9EQjr4Ar8SPukhnsTeS+kwX+9FyUI1o57k=     NaN  101353   \n",
       "3      ADL8ZENEcGUW3bCQg4t8gA0tJR9R6H5OYwr+TCPb5oY=    male    7503   \n",
       "4      5eCvpCJiXsYg8jNhQAz8JltX6G0LSWpFb86a2GVuinA=     NaN   12825   \n",
       "...                                             ...     ...     ...   \n",
       "54299  yY0/JhgPot0/jgNGGKXiM+r47EA6HyxjxL5HBCe5cJE=     NaN    6300   \n",
       "54300  1ISypO5ve8GgsJ2bgEW87eqdOIEAEqPfWeea52SndWo=    male   32937   \n",
       "54301  xoUBGAzyfHBkDa/YjwWn3zpZCzr3FUpAFd8qMj2fIcA=    male   17453   \n",
       "54302  ESAeVlIpxgtgb2EtZb8K+plFLqKch5ffAgRzKnQqTQ4=     NaN    2393   \n",
       "54303  hkZZTOTi9MpjU38ctwOSK3O4g12JZt2ykeYS7nJsJkc=  female  293891   \n",
       "\n",
       "       badges_cnt first_login_date_TW  user_grade user_city  has_teacher_cnt  \\\n",
       "0               1          2019-01-24           1        kh                0   \n",
       "1               1          2019-01-24           2      ntpc                0   \n",
       "2              11          2019-01-24           2        kh                1   \n",
       "3               0          2019-01-24           2        kh                1   \n",
       "4               2          2019-01-24           3      ntpc                1   \n",
       "...           ...                 ...         ...       ...              ...   \n",
       "54299           0          2019-01-23           9       ylc                1   \n",
       "54300           7          2019-01-23           9      ttct                1   \n",
       "54301           3          2019-01-23           9       chc                1   \n",
       "54302           2          2019-01-23          10        tc                1   \n",
       "54303          35          2019-01-23          12        tp                0   \n",
       "\n",
       "       is_self_coach  has_student_cnt  belongs_to_class_cnt  has_class_cnt  \\\n",
       "0              False                0                     0              0   \n",
       "1              False                0                     0              0   \n",
       "2              False                0                     1              0   \n",
       "3              False                0                     1              0   \n",
       "4              False                0                     1              0   \n",
       "...              ...              ...                   ...            ...   \n",
       "54299          False                0                     0              0   \n",
       "54300          False                0                     1              0   \n",
       "54301          False                0                     1              0   \n",
       "54302          False                0                     1              0   \n",
       "54303          False                0                     0              0   \n",
       "\n",
       "       problems_attempted  time_spent  average_level  correct_percentage  \\\n",
       "0                       1   43.000000       1.000000            1.000000   \n",
       "1                       1   31.000000       0.000000            1.000000   \n",
       "2                       3   22.666667       0.333333            0.666667   \n",
       "3                       1   32.000000       0.000000            1.000000   \n",
       "4                       1    9.000000       0.000000            1.000000   \n",
       "...                   ...         ...            ...                 ...   \n",
       "54299                   2   55.000000       0.000000            1.000000   \n",
       "54300                   1   15.000000       0.000000            1.000000   \n",
       "54301                   1   35.000000       0.000000            0.000000   \n",
       "54302                   2   15.000000       0.500000            1.000000   \n",
       "54303                   2    7.000000       0.000000            1.000000   \n",
       "\n",
       "       max_level  avg_learning_stage  avg_difficulty  average_hints  \n",
       "0            1.0                   1             0.0       1.000000  \n",
       "1            1.0                   0             0.0       0.000000  \n",
       "2            1.0                   1             0.0       0.333333  \n",
       "3            1.0                   0             0.0       0.000000  \n",
       "4            1.0                   0             0.0       0.000000  \n",
       "...          ...                 ...             ...            ...  \n",
       "54299        1.0                   0             1.0       0.000000  \n",
       "54300        1.0                   0             1.0       0.000000  \n",
       "54301        1.0                   0             1.0       1.000000  \n",
       "54302        1.0                   1             1.0       0.000000  \n",
       "54303        1.0                   0             0.0       0.500000  \n",
       "\n",
       "[54304 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    }
   ],
   "source": [
    "log(\"Preprocessing...\")\n",
    "user_features = U_features()\n",
    "X: pd.DataFrame = preprocess_df(df=X, o_features=user_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Cure Implementation\n",
    "Below is our custom CURE implementation, which will be used to perform clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,random\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "random.seed(3)\n",
    "np.random.seed(3)\n",
    "\"\"\" Sample size for initial clustering \"\"\"\n",
    "CURE_SAMPLE = lambda size: int(size / 5) if size < 1000 else int(size / 50)\n",
    "\n",
    "\"\"\" Number of (calculated, random) representative points \"\"\"\n",
    "CURE_REPRES = lambda sample_len: (10, 5)  # (calculated, random)\n",
    "\n",
    "\n",
    "def random_data_split(data: np.ndarray, n: int):\n",
    "    maxi = len(data)\n",
    "    indices = np.random.choice(maxi, n, replace=False)\n",
    "\n",
    "    def inverze():\n",
    "        mask = np.full(maxi, True)\n",
    "        mask[indices] = False\n",
    "        return mask\n",
    "\n",
    "    return data[indices], data[inverze()]\n",
    "\n",
    "\n",
    "def _cure_initial_clustering(sample: np.ndarray):\n",
    "    \"\"\"Initial clustering\n",
    "    idea:\n",
    "    - do a clustering\n",
    "    - drop tiny clusters\n",
    "    - calculate average distances in good-looking one\n",
    "    - do the sample clustering with DBSCAN\n",
    "    \"\"\"\n",
    "\n",
    "    def eps_calculation():\n",
    "        n_clusters = 4  # magic number\n",
    "        labels = KMeans(n_clusters=n_clusters, random_state=0, max_iter=500).fit(sample).labels_\n",
    "        partition = lambda k: sample[labels == k]\n",
    "\n",
    "        def cluster_averages():\n",
    "            for k in range(labels.max() + 1):\n",
    "                ds = np.triu(pairwise_distances(partition(k)))\n",
    "                yield np.average(ds[ds != 0])\n",
    "\n",
    "        averages = sorted(list(cluster_averages()))\n",
    "        arbitrary_choice = averages[1]\n",
    "        return arbitrary_choice\n",
    "\n",
    "    # intentionally not using AgglomerativeClustering\n",
    "    sample_len = len(sample)\n",
    "    correction = 0.5 if sample_len > 700 else 0.3\n",
    "    eps = correction * eps_calculation()\n",
    "    labels = DBSCAN(eps=eps, min_samples=10).fit(sample)\n",
    "    return labels.labels_\n",
    "\n",
    "\n",
    "def cure_classify(x: np.ndarray, representatives: np.ndarray) -> np.ndarray:\n",
    "    labels = np.ndarray(shape=(len(x),), dtype=int)\n",
    "\n",
    "    rss = np.concatenate(representatives)\n",
    "    indexed_rs = [\n",
    "        partition\n",
    "        for partition, rs in enumerate(representatives)\n",
    "        for _ in rs\n",
    "    ]\n",
    "\n",
    "    dss = pairwise_distances(x, rss)\n",
    "    for i in range(len(x)):\n",
    "        labels[i] = indexed_rs[dss[i].argmin()]\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def cure_representatives(x: np.ndarray):\n",
    "    # Checked initial clustering\n",
    "    while True:  # retry mechanism\n",
    "        try:\n",
    "            sample_num = CURE_SAMPLE(len(x))\n",
    "            sample, remainder = random_data_split(x, sample_num)\n",
    "            sample_labels = _cure_initial_clustering(sample)\n",
    "            if sample_labels.max() >= 1:  # sanity check\n",
    "                break\n",
    "            else:\n",
    "                print(\"Inappropriate initial clusters, retrying\")\n",
    "        except ValueError:\n",
    "            print(\"Failed EPS calculation, retrying\")\n",
    "\n",
    "    sample_partition = lambda k: sample[sample_labels == k]\n",
    "    centroid = lambda x: np.average(x, axis=0)\n",
    "\n",
    "    def calc_borderline(x: np.ndarray, desired: int):\n",
    "        cent = centroid(x)\n",
    "        # centroid <-> point distances\n",
    "        cent_point_dist: list[tuple[np.ndarray, float]] = sorted(\n",
    "            zip(x, pairwise_distances(x, [cent]).flatten()),\n",
    "            key=lambda p: p[1]\n",
    "        )\n",
    "\n",
    "        # furthest points from centroid\n",
    "        borderline: list[np.ndarray] = [cent_point_dist.pop()[0]]\n",
    "\n",
    "        half = int(len(cent_point_dist) / 2)\n",
    "        # an educated guess to reduce the number of points\n",
    "        cent_point_dist = cent_point_dist[half:]\n",
    "\n",
    "        while len(borderline) < desired:\n",
    "            def repres_distance(point):  # point <-> borderline \"distances\"\n",
    "                return pairwise_distances(borderline, [point]).sum()\n",
    "\n",
    "            ds = list(map(lambda pair: (pair[0], repres_distance(pair[0])), cent_point_dist))\n",
    "            ds = sorted(ds, key=lambda p: p[1])\n",
    "            borderline.append(ds[-1][0])\n",
    "\n",
    "        for vec in borderline:\n",
    "            vec_towards_centroid = cent - vec\n",
    "            yield vec + vec_towards_centroid / 4\n",
    "\n",
    "    def representatives(x) -> np.ndarray:\n",
    "        borderline_num, randoms_num = CURE_REPRES(len(x))\n",
    "        randoms, _ = random_data_split(x, randoms_num)\n",
    "        borderline = list(calc_borderline(x, borderline_num))\n",
    "        return np.concatenate([randoms, borderline])\n",
    "\n",
    "    rs = [\n",
    "        representatives(sample_partition(k))\n",
    "        for k in range(sample_labels.max() + 1)\n",
    "    ]\n",
    "\n",
    "    return rs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting users\n",
    "Before clustering, users are split into 5 categories. Afterwards, the CURE clustering is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting users...\n",
      "Cluster each instance of the split...\n",
      "Getting clusters for split1 users...\n",
      "Getting clusters for split2 users...\n",
      "Getting clusters for split3 users...\n",
      "Getting clusters for split4 users...\n",
      "Getting clusters for split5 users...\n"
     ]
    }
   ],
   "source": [
    "def split_users_by_grade(df):\n",
    "    split1 = df[df[\"user_grade\"] < 4]\n",
    "    split2 = df[df[\"user_grade\"] == 5]\n",
    "    split3 = df[df[\"user_grade\"] == 6]\n",
    "    split4 = df[df[\"user_grade\"] == 7]\n",
    "    split5 = df[df[\"user_grade\"] > 7]\n",
    "    return [split1, split2, split3, split4, split5], [\"split1\", \"split2\", \"split3\", \"split4\", \"split5\"]\n",
    "\n",
    "\n",
    "def cure_clustering(df: pd.DataFrame):\n",
    "    data = df.drop(columns=[\"uuid\"]).to_numpy()\n",
    "    cure_repres = cure_representatives(data)\n",
    "    cluster_labels = cure_classify(data, cure_repres)\n",
    "    n_clusters = cluster_labels.max() + 1\n",
    "    partition = lambda k: data[cluster_labels == k]\n",
    "    similarities = [pairwise_distances(partition(k)) for k in range(n_clusters)]\n",
    "    sim_users = [df[\"uuid\"][cluster_labels == k] for k in range(n_clusters)]\n",
    "    return cluster_labels, similarities, sim_users\n",
    "\n",
    "\n",
    "USE_USER_USER_SIMILARITY = True\n",
    "all_split_labels = []\n",
    "all_split_similarities = []\n",
    "all_split_sim_users = []\n",
    "\n",
    "log(\"Splitting users...\")\n",
    "dfs, labels = split_users_by_grade(X)\n",
    "del X\n",
    "\n",
    "log('Cluster each instance of the split...')\n",
    "for df, label in zip(dfs, labels):\n",
    "    log(\"Getting clusters for {} users...\".format(label))\n",
    "    cluster_labels, similarities, sim_users = cure_clustering(df)\n",
    "    all_split_labels.append(cluster_labels)\n",
    "    all_split_similarities.append(similarities)\n",
    "    all_split_sim_users.append(sim_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate clusters\n",
    "Now, we evaluate the clusters based on Davies-Bouldin score and centroid differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate clusters in each split\n",
      "---\n",
      "Split: split1 | Davies-Bouldin score:  20.03571091366961\n",
      "Centroid differences (for 5 clusters):\n",
      "[('problems_attempted', 0.8307715974445031), ('has_student_cnt', 0.32342093215925327), ('gender_unspecified', 0.08641757932175942)]\n",
      "[('problems_attempted', 12.31790686026934), ('avg_learning_stage', 0.5623079382115996), ('has_student_cnt', 0.4670455544888016)]\n",
      "[('problems_attempted', 5.9774523263262775), ('avg_learning_stage', 0.6530265253198464), ('has_student_cnt', 0.6261284619686445)]\n",
      "---\n",
      "Split: split2 | Davies-Bouldin score:  6.580712555735007\n",
      "Centroid differences (for 5 clusters):\n",
      "[('problems_attempted', 17.489206333761487), ('avg_learning_stage', 0.5153645812063183), ('has_student_cnt', 0.4990898298518053)]\n",
      "[('problems_attempted', 25.456553252496217), ('avg_learning_stage', 0.8029607965847395), ('points', 0.7268861069679096)]\n",
      "[('problems_attempted', 23.776854747985773), ('avg_learning_stage', 0.8077654176017228), ('points', 0.5112431032542564)]\n",
      "---\n",
      "Split: split3 | Davies-Bouldin score:  13.720210919987778\n",
      "Centroid differences (for 5 clusters):\n",
      "[('problems_attempted', 8.869337180565038), ('points', 0.3390669775297532), ('badges_cnt', 0.33265544486482646)]\n",
      "[('problems_attempted', 14.724664776009902), ('avg_learning_stage', 0.6072390441948788), ('points', 0.3295016851978827)]\n",
      "[('problems_attempted', 14.247114336754233), ('avg_learning_stage', 0.4956380458146302), ('points', 0.18202514397982278)]\n",
      "---\n",
      "Split: split4 | Davies-Bouldin score:  7.758062362670837\n",
      "Centroid differences (for 3 clusters):\n",
      "[('user_city_tn', 0.14248468293631428), ('average_hints', 0.0992478088063744), ('time_spent', 0.09525959470423312)]\n",
      "[('user_city_tn', 0.12096075267332382), ('gender_unspecified', 0.10643846587837968)]\n",
      "---\n",
      "Split: split5 | Davies-Bouldin score:  35.73865562831324\n",
      "Centroid differences (for 3 clusters):\n",
      "[('problems_attempted', 7.484869456602181), ('avg_learning_stage', 0.24390997918841895), ('badges_cnt', 0.15651970963904877)]\n",
      "[('problems_attempted', 0.39226312902783533), ('has_teacher_cnt', 0.25767859591389), ('belongs_to_class_cnt', 0.08479355746570856)]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "\n",
    "def evaluate_clusterings(combined):\n",
    "    for df, split, labels in combined:\n",
    "        df = df.drop(columns=[\"uuid\", \"first_login_date_TW\"])\n",
    "        data = df.to_numpy()\n",
    "        log(f\"Split: {split} | Davies-Bouldin score: \", davies_bouldin_score(data, labels))\n",
    "        centroids = [np.average(data[labels == k], axis=0) for k in range(labels.max() + 1)]\n",
    "\n",
    "        def interesting_columns(x: np.ndarray):\n",
    "            return list(filter(lambda pair: pair[1] > 0.07, zip(df.columns, x)))\n",
    "\n",
    "        c0 = centroids[0]\n",
    "        log(f\"Centroid differences (for {len(centroids)} clusters):\")\n",
    "        for i in range(1, min(4, len(centroids))):\n",
    "            c1 = centroids[i]\n",
    "            diff = interesting_columns(c0 - c1)\n",
    "            diff = sorted(diff, key=lambda p: p[1], reverse=True)[:3]\n",
    "            log(diff)\n",
    "        log('---')\n",
    "\n",
    "log('Evaluate clusters in each split')\n",
    "log('---')\n",
    "evaluate_clusterings(zip(dfs, labels, all_split_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system\n",
    "Below is the code used for the recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def construct_util_matrix(users,problems,test_index):\n",
    "    unique_problems = problems['upid'].unique()\n",
    "    M = np.empty((len(users),len(unique_problems)))\n",
    "    M_test = np.zeros_like(M)\n",
    "    for i, userID in enumerate(tqdm(users['uuid'],desc=\"Func: construct_util_matrix()\")):\n",
    "        user_problems = problems.loc[problems['uuid'] == userID]\n",
    "        if not user_problems.empty:\n",
    "            max_time = max(user_problems['total_sec_taken'])\n",
    "            user_prob_idx = []\n",
    "            user_difficulties = []\n",
    "            for j in user_problems.index.to_list():\n",
    "                problem_ID = user_problems.loc[[j],'upid'].values[0]\n",
    "                problem_index = np.where(unique_problems == problem_ID)[0][0]\n",
    "                user_prob_idx.append(problem_index)\n",
    "                time = user_problems.loc[[j],'total_sec_taken'].values[0]\n",
    "                is_correct = user_problems.loc[[j],'is_correct'].values[0]\n",
    "                user_difficulties.append(get_difficulty(time,max_time,is_correct))\n",
    "                M[i, problem_index] = user_difficulties[-1]\n",
    "\n",
    "            #standardize difficulty values between [0,1]\n",
    "            min_ = np.min(user_difficulties)\n",
    "            max_ = np.max(user_difficulties)\n",
    "            M[i,user_prob_idx] = (M[i,user_prob_idx] - min_) / (max_)\n",
    "            # Save 'true' difficulty measures and remove from utility matrix\n",
    "            for idx, prob_idx in enumerate(user_problems.index.to_list()):\n",
    "                if prob_idx in test_index:\n",
    "                    M_idx = user_prob_idx[idx]\n",
    "                    M_test[i, M_idx] = M[i, M_idx]\n",
    "                    M[i, M_idx] = 0.0\n",
    "        else:\n",
    "            #M = np.delete(M, i, axis=0)\n",
    "            pass\n",
    "    return M, M_test, unique_problems\n",
    "\n",
    "def get_difficulty(time,max_time,is_correct,alpha=0.8):\n",
    "    \"\"\"\n",
    "    :param time: Time (sec) spent on a given problem for a given student\n",
    "    :param max_time: Maximum time (sec) a given student has used on any problem\n",
    "    :param is_correct: boolean if the student solved the given problem (1) or not (0)\n",
    "    :param alpha: time importance weight\n",
    "    :defined in func beta: correctness importance weights (Note weights should sum to one)\n",
    "    :return: Relative difficulty of a problem for a given student\n",
    "    \"\"\"\n",
    "    beta = 1-alpha\n",
    "    difficulty = 1-((max_time - time) / max_time)*alpha - beta*is_correct\n",
    "    return difficulty\n",
    "\n",
    "def split_data(problems):\n",
    "    # Sort problems by timestamp - make sure that we only consider problems for the relevant users!\n",
    "    pr_user = problems.sort_values(by='timestamp_TW',ascending=False)\n",
    "    # Find out how many problems each user have attempted\n",
    "    prob_per_user = pr_user.groupby('uuid').size()\n",
    "    # Find 80 % quantile of how many problems each user have attempted\n",
    "    cutoff_problems = np.sort(prob_per_user.to_numpy())[int(len(prob_per_user)*0.8)]\n",
    "    # Index of all users that have attempted 'cutoff_problems' or more problems\n",
    "    user_idx = prob_per_user[prob_per_user>=cutoff_problems].index\n",
    "    # Find out how many users have attempted each problem\n",
    "    solved_per_prob = pr_user.groupby('upid').size()\n",
    "    # Find 80 % quantile of how many users have attempted each problem\n",
    "    cutoff_users = np.sort(solved_per_prob.to_numpy())[int(len(solved_per_prob) * 0.8)]\n",
    "    # Index of all problems where cutoff_users or more users have attempted the problem\n",
    "    prob_idx = solved_per_prob[solved_per_prob>=cutoff_users].index\n",
    "    # Filter data frame on both users and problems\n",
    "    user_sample = pr_user[pr_user['uuid'].isin(user_idx)]\n",
    "    prob_sample = user_sample[user_sample['upid'].isin(prob_idx)]\n",
    "    # Sample the last 5 attempted problems for each filtered user\n",
    "    test_index = prob_sample.groupby('uuid').head(int(cutoff_problems/5)).index.to_list()\n",
    "    return test_index\n",
    "\n",
    "def get_utility_matrix_shape(clusters,df_pr,subset=False):\n",
    "    if subset:\n",
    "        problems = defaultdict(list)\n",
    "        for userID in tqdm(clusters['uuid'],desc=\"Func: get_utility_matrix_shape()\"):\n",
    "            user_info = df_pr.loc[df_pr['uuid'] == userID]\n",
    "            # for problem in user_info['upid']:\n",
    "            if user_info['upid'].shape[0]:\n",
    "                problems[str(user_info['upid'])] = 1\n",
    "        sub_problems = df_pr['upid'].isin(problems)\n",
    "        df_pr_sub = df_pr.loc[sub_problems]\n",
    "        return clusters.shape[0], len(df_pr_sub['upid'].unique())\n",
    "    else:\n",
    "        return clusters.shape[0], len(df_pr['upid'].unique())\n",
    "\n",
    "\n",
    "def generate_utility_matrix_for_one_cluster(clusters,cluster_id,df_u_full,df_pr_full):\n",
    "    cluster = clusters.loc[clusters['labels'] == cluster_id]\n",
    "    sub_users = df_u_full['uuid'].isin(cluster['uuid'].to_list())\n",
    "    df_u_sub = df_u_full.loc[sub_users]\n",
    "\n",
    "    #problems = []\n",
    "    # for userID in tqdm(df_u_sub['uuid'],desc=\"Func: generate_utility_matrix_for_one_cluster()\"):\n",
    "    #     user_info = df_pr_full.loc[df_pr_full['uuid'] == userID]\n",
    "    #     for problem in user_info['upid']:\n",
    "    #         problems.append(problem)\n",
    "    # sub_problems = df_pr_full['upid'].isin(problems)\n",
    "    # df_pr_sub = df_pr_full.loc[sub_problems]\n",
    "    df_pr_sub = df_pr_full.loc[df_pr_full['uuid'].isin(df_u_sub['uuid'])]\n",
    "    test_index = split_data(df_pr_sub)\n",
    "    M, M_test, unique_prob_ids = construct_util_matrix(df_u_sub, df_pr_sub,test_index)\n",
    "    return M, M_test, df_u_sub['uuid'], unique_prob_ids\n",
    "\n",
    "\n",
    "def get_psedu_problem_difficulties(M, M_test,user_user_similarities_matrix,use_user_user_similarity):\n",
    "    errors = []\n",
    "    recommendations = np.zeros_like(M)  # Create copy of utility matrix, so that 'predictions' are not used when aggregating\n",
    "    for user_idx in tqdm(range(np.shape(M)[0]),desc=\"Func: get_psedu_problem_difficulties()\"):\n",
    "        user_similarity_vec = user_user_similarities_matrix[user_idx,:]\n",
    "        recommendations[user_idx, :], error = get_psedu_problem_difficulties_for_single_user(user_idx, M, M_test,user_similarity_vec,use_user_user_similarity)\n",
    "        errors.append(error)\n",
    "    return recommendations, errors\n",
    "\n",
    "\n",
    "\n",
    "def get_psedu_problem_difficulties_for_single_user(user_idx, M, M_test,user_sim_vector,use_user_user_similarity=False):\n",
    "    # Now that we have a utility matrix, we need to fill all empty entries\n",
    "    #M2 = np.copy(M)  # Create copy of utility matrix, so that 'predictions' are not used when aggregating\n",
    "    n_user = np.shape(M)[0]\n",
    "    n_problems = np.shape(M)[1]\n",
    "    user_recommendations = np.zeros(n_problems)\n",
    "    unsolved_problems = np.argwhere( M[user_idx, :] == 0.0)\n",
    "    unsolved_problems = [u[0] for u in unsolved_problems]\n",
    "    relevant_user_ids = list(range(0,user_idx))+list(range(user_idx+1,n_user))\n",
    "    relevant_M = M[relevant_user_ids,:][:,unsolved_problems]\n",
    "    if use_user_user_similarity:\n",
    "        #We need to turn distance measures into similarity, which is done by subtracting the distance from the maximum distance and normalizing\n",
    "        relevant_user_sim_vector = user_sim_vector[relevant_user_ids].max()-user_sim_vector[relevant_user_ids]\n",
    "        relevant_user_sim_vector =  ( relevant_user_sim_vector - np.min(relevant_user_sim_vector) ) / np.std(relevant_user_sim_vector)\n",
    "        #Next we want want to weight the non-zero inputs, such that the weights are equal to 1, to keep the scale of the difficuly.\n",
    "        weight_scale =  relevant_user_sim_vector @ (relevant_M > 0)\n",
    "        user_recommendations[unsolved_problems] = np.dot(relevant_user_sim_vector,relevant_M) / weight_scale #np.sum(relevant_M != 0, axis=0)\n",
    "    else:\n",
    "        user_recommendations[unsolved_problems] = np.sum(relevant_M, axis=0) / np.sum(relevant_M != 0, axis=0)\n",
    "\n",
    "    user_recommendations[np.isnan(user_recommendations)] = 0\n",
    "    test_idx = M_test[user_idx, :].nonzero()\n",
    "    errors = np.abs(user_recommendations[test_idx]-M_test[user_idx,test_idx])\n",
    "    return user_recommendations, errors\n",
    "\n",
    "def get_recommendation(difficulty_matrix,quantile=0.80,recommendations_to_return = 1):\n",
    "    if len(difficulty_matrix.shape) == 1:\n",
    "        difficulty_matrix = np.reshape(difficulty_matrix,(1,-1))\n",
    "\n",
    "    n_problems = np.min(np.sum(~np.isnan(difficulty_matrix),axis=1))\n",
    "    sorted_indices = np.argsort(difficulty_matrix,axis=1)\n",
    "\n",
    "    quantile_idx = int(n_problems*quantile)\n",
    "\n",
    "    #indices of problems being recommended (based on the initial ordering in difficulty_matrix)\n",
    "    problem_indices = sorted_indices[:,quantile_idx:quantile_idx+recommendations_to_return]\n",
    "    #test = difficulty_matrix[:,problem_indices]\n",
    "    difficulties_of_recommendations = [difficulty_matrix[user_idx, prob_idx] for (user_idx, prob_idx) in enumerate(problem_indices)]\n",
    "    return difficulties_of_recommendations, problem_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create utility matrix based on clustering and problem,user pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding clusters labels and uuids for all splits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running cluster:   0%|          | 0/5 [00:02<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bind_labels_and_uuid(cluster_labels, sim_users):\n",
    "    cluster_partitions = [cluster_labels[cluster_labels == i] for i in range(cluster_labels.max() + 1)]\n",
    "    clusters = pd.DataFrame([np.hstack(cluster_partitions), np.hstack(sim_users)]).T\n",
    "    clusters.columns = [\"labels\", \"uuid\"]\n",
    "    return clusters\n",
    "\n",
    "\n",
    "log(\"Binding clusters labels and uuids for all splits\")\n",
    "all_segment_clusters = [bind_labels_and_uuid(c_labels, s_users) for (c_labels, s_users) in\n",
    "                        zip(all_split_labels, all_split_sim_users)]\n",
    "\n",
    "\n",
    "def run_and_evaluate_recommender_system(clusters, df_pr, df_u, user_user_similarities, cluster_id=0,\n",
    "                                        use_user_user_similarity=False):\n",
    "    M, M_test, U1_ids, P1_ids = generate_utility_matrix_for_one_cluster(clusters=clusters, df_u_full=df_u,\n",
    "                                                                        df_pr_full=df_pr, cluster_id=cluster_id)\n",
    "\n",
    "    cluster_user_user_similarity = user_user_similarities[cluster_id]\n",
    "\n",
    "    difficulties_for_all_users, errors_all = get_psedu_problem_difficulties(M, M_test, cluster_user_user_similarity,\n",
    "                                                                            use_user_user_similarity)\n",
    "    errors = [item[0] for sublist in errors_all for item in sublist if len(item) > 0]\n",
    "    mean_abs_error = np.mean(errors)\n",
    "    recommendation_difficulty_for_all_users, recommendation_idx_all = get_recommendation(difficulties_for_all_users)\n",
    "    num_users = clusters.loc[clusters['labels'] == cluster_id].shape[0]\n",
    "    print(\"Mean absolute error of difficulty was {} for cluster {} with {} users and use_similarrity={}\".format(\n",
    "        mean_abs_error, cluster_id, num_users, str(use_user_user_similarity)))\n",
    "    return mean_abs_error, errors, recommendation_difficulty_for_all_users, recommendation_idx_all, np.mean(\n",
    "        difficulties_for_all_users[difficulties_for_all_users > 0])\n",
    "\n",
    "\n",
    "# Run all splits, and all clusters\n",
    "mean_errors = []\n",
    "for split_idx, clusters_ in enumerate(all_segment_clusters):\n",
    "    df_u_split = dfs[split_idx]\n",
    "    df_p_split = df_pr.loc[df_pr['uuid'].isin(df_u_split['uuid'])]\n",
    "    similarities_ = all_split_similarities[split_idx]\n",
    "    for cluster_idx in tqdm(range(len(similarities_)), desc=\"running cluster\"):\n",
    "        mean_abs_error, errors, recommendation_difficulty_for_all_users, recommendation_idx_all, mean_difficulty = run_and_evaluate_recommender_system(\n",
    "            clusters_, df_p_split, df_u_split, similarities_, cluster_idx, USE_USER_USER_SIMILARITY)\n",
    "        mean_errors.append(mean_abs_error)\n",
    "        with open(f'{DATA_FOLDER}/evaluation/eval_mean_errors_5splits.txt', 'a') as f:\n",
    "            f.write(\n",
    "                \"split_id: {},split_size: {}, cluster_id: {},cluster_u_size {}, n_errors: {}, mean_error: {}, mean_difficulty: {}, mean_recommendation_difficulty: {}\\n\".format(\n",
    "                    split_idx, df_u_split.shape[0], cluster_idx, similarities_[cluster_idx].shape[0],\n",
    "                    len(errors), np.round(mean_abs_error, 5), np.round(mean_difficulty, 5),\n",
    "                    np.round(np.mean(recommendation_difficulty_for_all_users), 5)))\n",
    "        with open(f'{DATA_FOLDER}/evaluation/eval_error_5splitss.txt', 'a') as f:\n",
    "            f.write(\"split_id: {}, cluster_id: {}, errors {}\\n\".format(split_idx, cluster_idx, errors))\n",
    "print(\"Mean absolute errors for the different splits {}\".format(mean_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see an error rate of ~0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
